{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Science and Machine Learning course - Batch-302**\n",
    "\n",
    "**Assignment-11 - ML-Evaluation**\n",
    "\n",
    "**Submission Date: 30/03/2025**\n",
    "\n",
    "**General Instructions for Assignment submission**\n",
    "- **Please zip all the files** - Python code with results, screenshots, text file, etc. Any file please zip all, and upload as a single file.\n",
    "- That zip file's name, keep it based on this template \"**dsmlbatch302_ASM11_<your_firstname>_<your_initial>.zip**\"\n",
    "- Upload File option will be present after clicking the \"Attempt Now\" button in the Assignments page\n",
    "- For clarity about the Assignment, **refer the class video recordings** or ask questions during the next session\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1)** What **Evaluation methods** are used to measure the performance of Clustering algorithms? Give answer in 3 to 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Silhouette Score – Measures how similar a point is to its own cluster compared to other clusters. Values range from -1 to 1; higher is better.\n",
    "\n",
    "2. Davies-Bouldin Index – Evaluates intra-cluster similarity and inter-cluster differences. Lower values indicate better clustering.\n",
    "\n",
    "3. Calinski-Harabasz Index – Ratio of between-cluster dispersion to within-cluster dispersion. Higher values suggest better-defined clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2)** How does **Clustering help in understanding the dataset?** Give answer in 3 to 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Groups similar data points, helping to reveal structure or distribution in data.\n",
    "\n",
    "2. It helps summarize large datasets by grouping similar instances.\n",
    "\n",
    "3. Clusters can help spot outliers or abnormal data points.\n",
    "\n",
    "4. It helps in finding similarities in the dataset which helps in further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3)** Can Confusion matrix be used to evaluate the **performance of Clustering algorithm**? If that is possible, then **what should we have before** being able to use that technique for evaluating Clustering algorithm? Give answer in 3 to 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Yes, it can be used to evaluate the performance of clustering algorithm.\n",
    "\n",
    "2. Since clustering is unsupervised, it doesn’t use labels. After clustering, map cluster labels to true class labels to build the confusion matrix.\n",
    "\n",
    "3. This mapping helps in understanding accuracy, precision, recall, etc.\n",
    "\n",
    "4. It's often used when applying clustering techniques to labeled datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4)** Take **3 ML Algorithms in each of Classification and Regression in Supervised Learning**, and write down ALL possible Hyperparameters for those Algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification Algorithms**\n",
    "1. Support Vector Classifier \n",
    "\n",
    "   - C : float, default=1.0\n",
    "\n",
    "   - kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf\n",
    "\n",
    "   - gamma{‘scale’, ‘auto’} or float, default=’scale\n",
    "\n",
    "2. Decision Tree Classifier\n",
    "\n",
    "   - criterion{“gini”, “entropy”, “log_loss”}, default=”gini”\n",
    "\n",
    "   - max_depth : int, default=None\n",
    "\n",
    "   - min_samples_split : int or float, default=2\n",
    "\n",
    "   - min_samples_leaf : int or float, default=1\n",
    "\n",
    "   - max_features : int, float or {“sqrt”, “log2”}, default=None\n",
    "\n",
    "   - max_leaf_nodes : int, default=None\n",
    "\n",
    "3. Logistics Regression\n",
    "\n",
    "   - penalty{‘l1’, ‘l2’, ‘elasticnet’, None}, default=’l2’\n",
    "\n",
    "   - Cf : loat, default=1.0\n",
    "\n",
    "   - solver{‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "\n",
    "### **Regression Algorithms**\n",
    "1. Support Vector Regressor\n",
    "\n",
    "   - C : float, default=1.0\n",
    "\n",
    "   - epsilon : float, default=0.0\n",
    "\n",
    "   - loss{‘epsilon_insensitive’, ‘squared_epsilon_insensitive’}, default=’epsilon_insensitive\n",
    "\n",
    "2.  Decision Tree Regressor\n",
    "\n",
    "    - criterion{“squared_error”, “friedman_mse”, “absolute_error”, “poisson”}, default=”squared_error”\n",
    "\n",
    "    - max_depth : int, default=None\n",
    "\n",
    "    - max_features : int, float or {“sqrt”, “log2”}, default=None\n",
    "\n",
    "    - min_samples_leaf : int or float, default=1\n",
    "\n",
    "    - min_samples_split : int or float, default=2.\n",
    "\n",
    "3. Random Forest Regressor\n",
    "\n",
    "   - n_estimatorsint, default=100\n",
    "\n",
    "   - bootstrapbool, default=True\n",
    "   \n",
    "   - n_jobsint, default=None\n",
    "\n",
    "   - oob_scorebool or callable, default=False.\n",
    "\n",
    "   - **criterion, max_depth are common for both Random Forest regressor and Decision Tree regressor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5)** Is **Elbow method in Clustering** a Hyperparameter Tuning technique? How Elbow method works? Give answer in 3 to 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Yes, Elbow method is a technique for choosing the optimal value of k (number of clusters), which is a hyperparameter.\n",
    "\n",
    "2. It plots the within-cluster sum of squares (WCSS) against various k values.\n",
    "\n",
    "3. The goal is to find a point (the \"elbow\") where WCSS starts decreasing slowly.\n",
    "\n",
    "4. This point balances model complexity with performance.\n",
    "\n",
    "5. Choosing k at the elbow point usually yields the most meaningful clusters."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
